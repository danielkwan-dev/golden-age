# MIDAS ML Configuration â€” YOLOv11 + OpenCV

# Device categories the model can detect
device_types:
  - smartphone

# Fault classes (YOLO class labels, must match merged data.yaml order)
fault_classes:
  - phone              # 0: intact phone detected
  - phone_damage       # 1: general phone damage
  - body_lecet         # 2: body scratch
  - body_retak         # 3: body crack
  - lcd_garis          # 4: LCD line/streak
  - lcd_retak          # 5: LCD crack
  - lcd_rusak          # 6: LCD broken/dead
  - smartphone         # 7: smartphone device detection

# YOLOv11 model
model:
  variant: "yolo11n"            # yolo11n | yolo11s | yolo11m | yolo11l | yolo11x
  task: "detect"                # detect | segment
  image_size: 640
  num_classes: 8
  pretrained: true

# Training
training:
  epochs: 25
  batch_size: 16
  learning_rate: 0.01
  optimizer: "AdamW"
  patience: 20                  # early stopping patience
  device: "cpu"                  # GPU id (e.g. "0"), or "cpu"
  workers: 4
  augment: true
  val_split: 0.15
  seed: 42
  resume: false

# Audio / speech-to-text
audio:
  whisper_model: "base"
  sample_rate: 16000
  chunk_duration_sec: 5

# Inference
inference:
  confidence_threshold: 0.4
  iou_threshold: 0.45
  max_detections: 10
  frame_sample_interval: 5     # analyze every Nth frame
  device: "cpu"
  show_labels: true
  show_confidence: true
  overlay_alpha: 0.4           # transparency for overlay drawings

# Data paths (relative to ml/)
data:
  dataset_root: "data/merged"
  images_dir: "images"
  labels_dir: "labels"
  audio_dir: "audio_clips"
  checkpoint_dir: "runs"
  dataset_yaml: "data/merged/data.yaml"
